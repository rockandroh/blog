---
title: 키움 API Tick Data - Task2
author: ~
date: '2021-01-27'
slug: api-tick-data-task1-complete-3
description: "This is description"
thumbnail: /blog/pic/latency_jan_21.png
categories:
  - highfrequency
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 4
---

<img src="/blog/pic/latency_jan_21.png"
  align="center"
  width="600"
  style="background-color: white; padding-right: 0px;"
/>

<style>
div.rcode pre { background-color:#fffff0; }
div.rcode pre.r { background-color:#EDF6FA; }
</style>

<style>
div.pycode pre { background-color:#fffff0; }
div.pycode pre.python { background-color:#FFE9E9; }
</style>


<style type="text/css">

body, td {
   font-size: 14px;
}
code.r{
  font-size: 12px;
}
pre {
  font-size: 12px
}
</style>

***

*__Note__: 이 페이지는 키움 API를 통해 Real Time Tick Data를 받아온 후 데이터를 클리닝 하는 과정을 보여주고 있습니다. 오류 및 문의사항은 metrics@kakao.com 으로 메일주시면 감사하겠습니다*

**데이터 자체에 대한 질문과 데이터 제공에 관한 문의는 000 으로 메일 주시면 감사하겠습니다**

**R code 블럭과 Python code 블럭은 다음과 같이 색깔로 구분하겠습니다. 결과창은 동일하게 Ivory 색 블럭으로 표시됩니다.**

<div class = "rcode">
```{r}
# "이것은 R 코드 입니다."
```
</div>

<div class = "pycode">
```{python}
# "이것은 Python 코드 입니다."
```
</div>

# TASK2: Cleaning

* Package
```{r, warning=FALSE, message=FALSE, error=FALSE}
library(dplyr)
library(tidyverse)
library(DT)
library(reticulate) # Python
#py_install(packages = "matplotlib")
#py_install(packages = "pandas")
#py_install(packages = 'dfply')
library(highfrequency)

options(scipen=999)
options(max.print = 99999999)
options(digits=10)
```

* Import Data

- Check NA

<div class = "rcode">
```{r, warning=FALSE, message=FALSE, error=FALSE}
#wd = "G:/공유 드라이브/Project_TBD/Stock_Data/real_time/kiwoom_stocks/2021-01-14"
wd2 = "/Volumes/GoogleDrive/공유 드라이브/Project_TBD/Stock_Data/real_time/kiwoom_stocks/2021-01-26"
tbl =
  list.files(path = wd2, pattern = '.*stocks_trade.*\\.csv') %>%
  map_df(~readr::read_csv(paste(wd2,.,sep = '/'),
                          col_names = c('code','trade_date','timestamp','price','open','high','low','size','cum_size','ask1','bid1','rotation','bs_ratio', 'mkt_type', 'mkt_cap'),
                          col_types = cols(.default="d", code = "c")
                   )
         )

sum(is.na(tbl))
gc()
dim(tbl)
head(tbl)
```
</div>


## 1.타임 스탬프 Sort 하기

키움 API를 통해서 데이터를 받자마자 Timestamp를 찍고 DB에 저장하는데 저장되는 순서는 데이터 들어오는 순서와 다르므로 Timestamp를 다시한번 Sort 해주어야 한다.

## 2. 장중 데이터만 가지고 오기

Exchangehours Only!

키움 API 290 장구분
- 장전시간외: 1
- 장중: 2
- 장후시간외: 3

<div class = "rcode">
```{r}
df = 
  tbl %>%
  filter(mkt_type==2) %>%
  mutate_at(vars(timestamp), function(x) x*1000) %>%
  arrange(.,timestamp) %>%
  mutate(DATE = paste(substr(as.character(timestamp),1,4),
                      substr(as.character(timestamp),5,6),
                      substr(as.character(timestamp),7,8),
                      sep ="-" 
                      )) %>%
  mutate(TIME = paste(substr(as.character(timestamp),9,10),
                      substr(as.character(timestamp),11,12),
                      paste(substr(as.character(timestamp),13,14),
                            substr(as.character(timestamp),15,18),
                            sep='.'),
                      sep =":" 
                      )) %>%
  rename(SYMBOL = code) %>%
  rename(BID = bid1) %>%
  rename(OFR = ask1) %>%
  rename(SIZE = size)
  
  
head(df)
  
gc()
tail(tbl, 20)
```
</div>

## 네이버 금융에서 주식티커 크롤링 

출처: https://hyunyulhenry.github.io/quant_cookbook/%ED%81%AC%EB%A1%A4%EB%A7%81-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0.html

```{r, echo=FALSE}
library(rvest)
library(httr)
data = list()

# i = 0 은 코스피, i = 1 은 코스닥 종목
for (i in 0:1) {

  ticker = list()
  url =
    paste0('https://finance.naver.com/sise/',
             'sise_market_sum.nhn?sosok=',i,'&page=1')
  
  down_table = GET(url)
  
  # 최종 페이지 번호 찾아주기
  navi.final = read_html(down_table, encoding = "EUC-KR") %>%
      html_nodes(., ".pgRR") %>%
      html_nodes(., "a") %>%
      html_attr(.,"href") %>%
      strsplit(., "=") %>%
      unlist() %>%
      tail(., 1) %>%
      as.numeric()
  
  # 첫번째 부터 마지막 페이지까지 for loop를 이용하여 테이블 추출하기
  for (j in 1:navi.final) {
    
    # 각 페이지에 해당하는 url 생성
    url = paste0(
      'https://finance.naver.com/sise/',
      'sise_market_sum.nhn?sosok=',i,"&page=",j)
    down_table = GET(url)
 
    Sys.setlocale("LC_ALL", "English")
    # 한글 오류 방지를 위해 영어로 로케일 언어 변경
 
    table = read_html(down_table, encoding = "EUC-KR") %>%
      html_table(fill = TRUE)
    table = table[[2]] # 원하는 테이블 추출
 
    Sys.setlocale("LC_ALL", "Korean")
    # 한글을 읽기위해 로케일 언어 재변경
 
    table[, ncol(table)] = NULL # 토론식 부분 삭제
    table = na.omit(table) # 빈 행 삭제
    
    # 6자리 티커만 추출
    symbol = read_html(down_table, encoding = "EUC-KR") %>%
      html_nodes(., "tbody") %>%
      html_nodes(., "td") %>%
      html_nodes(., "a") %>%
      html_attr(., "href")
 
    symbol = sapply(symbol, function(x) {
        str_sub(x, -6, -1) 
      })
    
    symbol = unique(symbol)
    
    # 테이블에 티커 넣어준 후, 테이블 정리
    table$N = symbol
    colnames(table)[1] = "종목코드"

    rownames(table) = NULL
    ticker[[j]] = table
 
    Sys.sleep(0.5) # 페이지 당 0.5초의 슬립 적용
  }
  
  # do.call을 통해 리스트를 데이터 프레임으로 묶기
  ticker = do.call(rbind, ticker)
  data[[i + 1]] = ticker
}

# 코스피와 코스닥 테이블 묶기
data = do.call(rbind, data)
```


## Symbol 별로 분리

Seperate by Ticker

```{r}
# Split by ticker
split_by_ticker <- function(data, output_location, date, TAQ=trades)
{  
  cols = c("SYMBOL","DATE","TIME","PRICE","SIZE","G127","CORR","COND","EX")

  for(s in levels(data$SYMBOL))
  {
    subset = data[data$SYMBOL == s,]
    
    for(col in col.trades)
    {
      idx = which(colnames(subset) %in% col)
      if(length(idx) == 0)
        subset[,col] = rep(0,dim(subset)[1])
    }
    subset = subset[,col.trades]
    fname = paste(s,"_",date,"_trades.csv",sep="")
    write.csv(subset,file=fname,row.names=FALSE)
  }
}
```


<div class = "pycode">
```{python, echo = FALSE}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime, timedelta
#py_install(packages = "matplotlib")
#py_install(packages = "pandas")
pd.options.display.float_format = '{:.4f}'.format
pd.set_option('display.max_rows', 100)
df_py = r.tbl
df_py.head()
```
</div>

```{r, include=FALSE, warning=FALSE, message=FALSE, error=FALSE}
rm(list = "tbl")
gc()
```

# Task1: 레이턴시 계산

* 레이턴시 키움 API에서 제공하는 시간과 제공받은 시점에 기록한 로컬 시스템 시간과의 차이를 의미한다. 레이턴시를 없애야만 나중에 실시간 거래를 하는데 문제가 없다. 개장 이후 거래량이 가장 큰 첫 30분동안에 특히 레이턴시가 매우 심한 것을 확인 할 수 있다. 

## 0. Filtering Samsung Stock

- KOSPI Code for Samsung Electronics is '005930'

<div class = "pycode">
```{python}
ss = df_py[df_py.code == '005930'].reset_index(drop=True)
ss.head(20)
```
</div>

## 1. Use time object in python

* Delete rows where "second" does not lie between 0 and 59.
* Substring the time stamp to get each time component (e.g., hour, minute, second, etc)

<div class = "pycode">
```{python}
ss = ss[ss['timestamp'].apply(lambda x: int(str(int(x*1000000))[12:14])) < 60 ]

ss = ss.assign( microsecond = ss['timestamp'].apply(lambda x: str(int(x*1000000))[14:20]),
                second = ss['timestamp'].apply(lambda x: str(int(x*1000000))[12:14]),
                minute = ss['timestamp'].apply(lambda x: str(int(x*1000000))[10:12]),
                hour = ss['timestamp'].apply(lambda x: str(int(x*1000000))[8:10]),
                day = ss['timestamp'].apply(lambda x: str(int(x*1000000))[6:8]),
                month = ss['timestamp'].apply(lambda x: str(int(x*1000000))[4:6]),
                year = ss['timestamp'].apply(lambda x: str(int(x*1000000))[0:4]),
                kw_time = ss['trade_date'].apply(lambda x: str(int(x))))
ss.head()
```
</div>

* Transform data type to str to use substring to make the format like "%Y-%m-%d %H:%M:%S.%f"
* We calculate the latency by subtracting 'trade_date' from the 'timestamp'

<div class = "pycode">
```{python}
ss['lc_time'] = ss.apply(lambda x: datetime(
                  year = int(x['year']),
                  month = int(x['month']),
                  day = int(x['day']),
                  hour = int(x['hour']),
                  minute = int(x['minute']),
                  second = int(x['second']),
                  microsecond = int(x['microsecond'])), #.strftime("%H:%M:%S.%f")[:-3], 
                  axis=1)

```
</div>

<div class = "pycode">
```{python}
ss['lc_time_hms'] = ss.apply(lambda x: x['lc_time'].strftime("%H:%M:%S"),
                             axis=1)
ss.head(10)
```
</div>

## 2. Calculate latency and clean it

* Calculate the latency by subtracting the time provided by Kiwoom dataset and self-recorded time at the moment of processing the data delivered through the Kiwoom API.

#### 오전 8시 9시 앞에 '0'을 붙여주기

<div class = "pycode">
```{python}
ss['kw_time'].apply(lambda x: x[0:2]).value_counts()
```
</div>


<div class = "pycode">
```{python}
ss['kw_time'] = ss.kw_time.apply(lambda x: '0' + x if ((x[0]=='8') | (x[0]=='9')) else x)
ss['kw_time'].apply(lambda x: x[0:2]).value_counts()
```
</div>

* 키움 타임 만들기

<div class = "pycode">
```{python}
ss['kw_time'] = ss.apply(lambda x: datetime(year = int(x['year']),
                                           month = int(x['month']),
                                           day = int(x['day']),
                                           hour = int(x['kw_time'][0:2]),
                                           minute = int(x['kw_time'][2:4]),
                                           second = int(x['kw_time'][4:6])),
                                           axis = 1
                                           )
                                           
ss['kw_time_hms']= ss.apply(lambda x: x['kw_time'].strftime("%H:%M:%S"),
                             axis=1)
```
</div>


#### Latency +/- 정보 가지고 오기

* Latency가 $+$ 인 경우 = 로컬 타임이 키움 타임보다 늦는 경우
* Latency가 $-$ 인 경우 = 로컬 타임이 키움 타임보다 빠른 경우 (weird)  

<div class = "pycode">
```{python}
ss['latency'] = (pd.to_datetime(ss['lc_time_hms']) - pd.to_datetime(ss['kw_time_hms'])).dt.total_seconds()
```
</div>

<div class = "pycode">
```{python}
ss.latency
```
</div>

<div class = "pycode">
```{python}
# x coordinates for the lines

xcoords = [ ss.index[ss['kw_time_hms'] == '09:05:00'][0], 
            ss.index[ss['kw_time_hms'] == '09:10:00'][0],
            ss.index[ss['kw_time_hms'] == '09:20:00'][0] ]

# colors for the lines
colors = ['darkgreen','green','limegreen']

time = ['09:05:00','09:10:00','09:20:00']

plt.scatter(ss.reset_index().index, ss.latency)
for xc,c,time in zip(xcoords,colors,time):
    plt.axvline(x=xc, label='{}'.format(time), c=c)
plt.legend()
plt.title('Latency Over Time on Jan 26')
plt.ylabel('Seconds')
```
</div>

<div class = "pycode">
```{python}
ss.latency.hist()
plt.title('Histogram of latency on Jan 26')
```
</div>

***

## Source

- 데이터 provided by 00 Team
- "https://stackoverflow.com/questions/8408397/python-timedelta-issue-with-negative-values"

---